

\subsection{API REST de CloudNAO}
\label{chapter_two/desc_cloudnao:api-rest-de-cloudnao}

Esta interfaz es el producto de la integración de modelos de aprendizaje
automático
enfocados a casos de uso relacionados con la robótica.
Es uno de los componentes más importantes en toda la arquitectura,
es el que une los servicios web de
terceros, los módulos mantenidos por el LAR y los entrega en una sola API.
Es un cliente y servidor a la vez.


\subsubsection{Descripción de la API}
\label{\detokenize{chapter_two/desc_cloudnao:documentacion-para-desarrolladores-clientes}}
La API REST de CloudNAO permite integrar dentro de una aplicación un
conjunto de herramientas para el análisis de imágenes.
Todas éstas basadas en modelos de aprendizaje automático. El URL base al
que todos los recursos son relativos es \sphinxcode{http://132.248.180.17/}.

La API tiene tres recursos:
\begin{itemize}
\item {} 
\sphinxcode{/register}: para que un nuevo usuario se registre y pueda ocupar los otros recursos. Envía una dirección de correo y una contraseña.

\item {} 
\sphinxcode{/refreshtoken}: para que el usuario pueda obtener un nuevo token de acceso al enviar los datos con los que se registró.

\item {} 
\sphinxcode{/vision}: el recurso más importante. Se le solicita que haga procesamiento de imágenes.

\end{itemize}

\paragraph{Vision}
\label{\detokenize{chapter_two/desc_cloudnao:vision}}
Este recurso es el encargado de la detección de características en una
imagen. Estas características son: la \sphinxstylestrong{detección de objetos}, el
\sphinxstylestrong{reconocimiento de rostros}, de personas previamente guardadas o de
nuevos sujetos para su almacenamiento, la \sphinxstylestrong{clasificación en cuatro escenarios}, lugares
dentro del laboratorio de algoritmos para la robótica, la
\sphinxstylestrong{detección de etiquetas o categorías}
y la \sphinxstylestrong{traducción de texto encontrado en una imagen}.

En este recurso la única forma de persistencia de datos es al guardar el
rostro de una nueva persona para su posterior reconocimiento.


\texttt{POST /vision}
\label{\detokenize{chapter_two/desc_cloudnao:post-vision}}\\

Se envía una imagen ya sea codificada en base 64 o mediante su URL y
las características que se desean obtener. Las características disponibles
son las siguientes:

\begin{itemize}
    \item{}
    \sphinxcode{FACE\_ENROLL}:
Detecta un rostro en la imagen y
con un identificador enviado en
el cuerpo de la petición se
almacena en una galería de
Kairos. Se emplea
\sphinxhref{https://www.kairos.com/docs/api/\#post-enroll}{/enroll}
de Kairos.
\item{}
\sphinxcode{FACE\_RECOGNITION}:
Encuentra rostros dentro de una
imagen y los relaciona con los
rostros similares previamente
guardados en una galería de
Kairos. Usa
\sphinxhref{https://www.kairos.com/docs/api/\#post-recognize}{/recognize}
de la API de Kairos.
\item{}
\sphinxcode{OBJECT\_DETECTION}:
Busca objetos en una la imagen,
usa la API de \sphinxhref{https://github.com/tensorflow/models/tree/master/research/object\_detection}{Tensorflow object
detection}.
Regresa las coordenadas de un
cuadro delimitador para cada
objeto detectado.
\item{}
\sphinxcode{LABELS\_DETECTION}:
Clasifica una imagen en distintas
categorías. Se vale de la API de
\sphinxhref{https://cloud.google.com/vision/docs/detecting-labels}{Google Cloud
Vision}
\item{}
\sphinxcode{OCR\_TRANSLATION}:
Lleva a cabo el reconocimiento de
texto en una imagen, para
posteriormente traducirlo.
Utiliza la API de \sphinxhref{https://cloud.google.com/vision/docs/ocr}{Google Cloud
Vision}
para el reconocimiento de
caracteres y la de \sphinxhref{https://cloud.google.com/translate/?hl=es}{Google Cloud
Translation}
para la segunda parte del proceso.
\item{}
\sphinxcode{CLASSIFY\_INDOOR\_SCENES}:
Clasifica una imagen en cuatro
categorías. Cada categoría es un
lugar dentro del área del LAR.

\end{itemize}


\subparagraph{Solicitud}
\label{\detokenize{chapter_two/desc_cloudnao:peticion}}

\subparagraph{Headers.}
\label{\detokenize{chapter_two/desc_cloudnao:headers}}
En los encabezados de la petición debe de ir el tipo de contenido que se envía
y un token de acceso único para cada usuario registrado. Esto último
simplemente es para evitar que cualquiera pueda hacer peticiones a la API.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Content}\PYG{o}{\PYGZhy{}}\PYG{n}{Type}\PYG{p}{:} \PYG{n}{application}\PYG{o}{/}\PYG{n}{json}
\PYG{n}{Authorization}\PYG{p}{:} \PYG{n}{ACCESS\PYGZus{}TOKEN}
\end{sphinxVerbatim}


\subparagraph{\sphinxstylestrong{Cuerpo.}}
\label{\detokenize{chapter_two/desc_cloudnao:body}}
En el cuerpo del mensaje se envía un JSON con la siguiente estructura. En la tabla 
\ref{tab:body_json_schema_request} se describen los atributos del JSON.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}imageContent\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
  \PYG{l+s+s2}{\PYGZdq{}imageSource\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
  \PYG{l+s+s2}{\PYGZdq{}features\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
    \PYG{p}{\PYGZob{}}
      \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}subjectID\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}
    \PYG{p}{\PYGZcb{}}
  \PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\begin{table}[h!]
\caption{Descripción de los elementos del JSON del cuerpo de la solicitud.\label{tab:body_json_schema_request}}
\begin{tabular}{|l|l}
\hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\textbf{Propiedades}}                                                                                                                                                                                                      \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}imageContent}                                                                                                                                                                                                              \\ \hline
Tipo de dato & \multicolumn{1}{l|}{string}                                                                                                                                                                                                      \\ \hline
Descripción  & \multicolumn{1}{l|}{Imagen codificada en base 64.}                                                                                                                                                                               \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}imageSource}                                                                                                                                                                                                               \\ \hline
Tipo de dato & \multicolumn{1}{l|}{string}                                                                                                                                                                                                      \\ \hline
Descripción  & \multicolumn{1}{l|}{URL público de la imagen.}                                                                                                                                                                                   \\ \hline
\multicolumn{2}{|l|}{features}                                                                                                                                                                                                                  \\ \hline
Tipo de dato & \multicolumn{1}{l|}{array}                                                                                                                                                                                                       \\ \hline
\multirow{4}{*}{Descripción}  & 
\multicolumn{1}{l|}{
Una arreglo de las características que se desean detectar
en la} \\
&
\multicolumn{1}{l|}{imagen. Se debe solicitar al menos una de las seis disponibles.} \\&
\multicolumn{1}{l|}{Por ejemplo FACE\_ENROLL, FACE\_RECOGNITION,} \\& 
\multicolumn{1}{l|}{CLASSIFY\_INDOOR\_SCENES, etc.}


\\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\textbf{Campos obligatorios}}                                                                                                                                                                                              \\ \hline
\multicolumn{2}{|l|}{imageContent}                                                                                                                                                                                                              \\
\multicolumn{2}{|l|}{imageSource}                                                                                                                                                                                                               \\
\multicolumn{2}{|l|}{features}                                                                                                                                                                                                                  \\ \hline
\end{tabular}
\end{table}



% \begin{sphinxVerbatim}[commandchars=\\\{\}]
% \PYG{p}{\PYGZob{}}
%   \PYG{l+s+s2}{\PYGZdq{}\PYGZdl{}schema\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}http://json\PYGZhy{}schema.org/draft\PYGZhy{}04/schema\PYGZsh{}\PYGZdq{}}\PYG{p}{,}
%   \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}object\PYGZdq{}}\PYG{p}{,}
%   \PYG{l+s+s2}{\PYGZdq{}properties\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
%     \PYG{l+s+s2}{\PYGZdq{}imageContent\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
%       \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}string\PYGZdq{}}\PYG{p}{,}
%       \PYG{l+s+s2}{\PYGZdq{}description\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Imagen codificada en base 64\PYGZdq{}}
%     \PYG{p}{\PYGZcb{}}\PYG{p}{,}
%     \PYG{l+s+s2}{\PYGZdq{}imageSource\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
%       \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}string\PYGZdq{}}\PYG{p}{,}
%       \PYG{l+s+s2}{\PYGZdq{}description\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}URL de la imagen\PYGZdq{}}
%     \PYG{p}{\PYGZcb{}}\PYG{p}{,}
%     \PYG{l+s+s2}{\PYGZdq{}features\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
%       \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}array\PYGZdq{}}\PYG{p}{,}
%       \PYG{l+s+s2}{\PYGZdq{}description\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Una arreglo de las características que se desean detectar en la imagen. Se debe solicitar al menos una de las seis disponibles. Por ejemplo FACE\PYGZus{}ENROLL, FACE\PYGZus{}RECOGNITION, CLASSIFY\PYGZus{}INDOOR\PYGZus{}SCENES, etc.\PYGZdq{}}
%     \PYG{p}{\PYGZcb{}}
%   \PYG{p}{\PYGZcb{}}\PYG{p}{,}
%   \PYG{l+s+s2}{\PYGZdq{}required\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
%     \PYG{l+s+s2}{\PYGZdq{}imageContent\PYGZdq{}}\PYG{p}{,}
%     \PYG{l+s+s2}{\PYGZdq{}imageSource\PYGZdq{}}\PYG{p}{,}
%     \PYG{l+s+s2}{\PYGZdq{}features\PYGZdq{}}
%   \PYG{p}{]}
% \PYG{p}{\PYGZcb{}}
% \end{sphinxVerbatim}


\subparagraph{\sphinxstylestrong{Respuesta}}
\label{\detokenize{chapter_two/desc_cloudnao:respuesta}}

\subparagraph{\sphinxstylestrong{Cuerpo.}}
\label{\detokenize{chapter_two/desc_cloudnao:id1}}
En el cuerpo del mensaje de respuesta si se obtiene un código 200
se obtiene un JSON con las características encontradas. En éste también
se incluyen mensajes de error que no pertenecen al estándar del protocolo HTTP.
En la tabla \ref{tab:json_schema_response} se describen los atributos del JSON.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}features\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}faceRecognition\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
      \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}subjectId\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}
      \PYG{p}{\PYGZcb{}}
    \PYG{p}{]}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}objectDetection\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
      \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}category\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}
      \PYG{p}{\PYGZcb{}}
    \PYG{p}{]}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}labelsDetection\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
      \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}name\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}
      \PYG{p}{\PYGZcb{}}
    \PYG{p}{]}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}ocrTranslation\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
      \PYG{l+s+s2}{\PYGZdq{}sourceText\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}targetText\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}sourceLanguage\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}faceEnroll\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
      \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{1}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}gender\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}
    \PYG{p}{\PYGZcb{}}
    \PYG{l+s+s2}{\PYGZdq{}indoorScenesClassify\PYGZdq{}} \PYG{o}{:} \PYG{p}{\PYGZob{}}
      \PYG{l+s+s2}{\PYGZdq{}indoorScene\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Hello, world!\PYGZdq{}}
    \PYG{p}{\PYGZcb{}}
  \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{longtable}{|l|l|}
\caption{Atributos que componen el JSON del cuerpo de la respuesta.\label{tab:json_schema_response}}\\
\hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{features}}                                                                                                                                \\ \hline
\endfirsthead
%
\endhead
%
\cellcolor[HTML]{68CBD0}\textbf{Tipo de dato} & objeto                                                                                                                                         \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\textbf{Propiedades}}                                                                                                                             \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{faceRecognition}}                                                                                                                         \\ \hline
Tipo de dato                                  & array                                                                                                                                          \\ \hline
Descripción                                   & \begin{tabular}[c]{@{}l@{}}Un arreglo de objetos que contienen \\ a los rostros reconocidos.\end{tabular}                                      \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{objectDetection}}                                                                                                                         \\ \hline
Tipo de dato                                  & array                                                                                                                                          \\ \hline
Descripción                                   & Contiene un arreglo con todos los objetos detectados.                                                                                          \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{labelsDetection}}                                                                                                                         \\ \hline
Tipo de dato                                  & array                                                                                                                                          \\ \hline
Descripción                                   & Contiene un arreglo con las etiquetas de la imagen.                                                                                            \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{ocrTranslation}}                                                                                                                          \\ \hline
\cellcolor[HTML]{FFFFFF}Tipo de dato          & objeto                                                                                                                                         \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{FFFFFF}Propiedades}                                                                                                                                      \\ \hline
\multicolumn{2}{|l|}{\texttt{sourceText}}                                                                                                                                                      \\ \hline
Tipo de dato                                  & string                                                                                                                                         \\ \hline
Descripción                                   & El texto en formato UTF-8.                                                                                                                     \\ \hline
\multicolumn{2}{|l|}{\texttt{targetText}}                                                                                                                                                      \\ \hline
Tipo de dato                                  & string                                                                                                                                         \\ \hline
Descripción                                   & El texto traducido.                                                                                                                            \\ \hline
\multicolumn{2}{|l|}{\texttt{sourceLanguage}}                                                                                                                                                  \\ \hline
Tipo de dato                                  & string                                                                                                                                         \\ \hline
Descripción                                   & El idioma original.                                                                                                                            \\ \hline
Descripción                                   & Un objecto con el texto encontrado en la imagen.                                                                                               \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{faceEnroll}}                                                                                                                              \\ \hline
Tipo de dato                                  & objeto                                                                                                                                         \\ \hline
\multicolumn{2}{|l|}{Propiedades}                                                                                                                                                              \\ \hline
\multicolumn{2}{|l|}{\texttt{topLeftX}}                                                                                                                                                        \\ \hline
Tipo de dato                                  & number                                                                                                                                         \\ \hline
Descripción                                   & Coordenada sobre el eje x.                                                                                                                     \\ \hline
\multicolumn{2}{|l|}{\texttt{topLeftY}}                                                                                                                                                        \\ \hline
Tipo de dato                                  & number                                                                                                                                         \\ \hline
Descripción                                   & Coordenada                                                                                                                                     \\ \hline
\multicolumn{2}{|l|}{\texttt{width}}                                                                                                                                                           \\ \hline
Tipo de dato                                  & number                                                                                                                                         \\ \hline
Descripción                                   & Ancho del recuadro que delimita la imagen.                                                                                                     \\ \hline
\multicolumn{2}{|l|}{\texttt{height}}                                                                                                                                                          \\ \hline
Tipo de dato                                  & number                                                                                                                                         \\ \hline
Descripción                                   & Altura del recuadro que delimita la imagen.                                                                                                    \\ \hline
\multicolumn{2}{|l|}{\texttt{confidence}}                                                                                                                                                      \\ \hline
Tipo de dato                                  & number                                                                                                                                         \\ \hline
Descripción                                   & Valor de 0-1 que representa una probabilidad.                                                                                                  \\ \hline
\multicolumn{2}{|l|}{\texttt{gender}}                                                                                                                                                          \\ \hline
Tipo de dato                                  & string                                                                                                                                         \\ \hline
Descripción                                   & Sexo de la persona con ese rostro (M o F)                                                                                                      \\ \hline
Descripción                                   & Características del rostro detectado.                                                                                                          \\ \hline
\multicolumn{2}{|l|}{\cellcolor[HTML]{68CBD0}\texttt{indoorScenesClassify}}                                                                                                                    \\ \hline
Tipo de dato                                  & objeto                                                                                                                                         \\ \hline
\multicolumn{2}{|l|}{Propiedades}                                                                                                                                                              \\ \hline
\multicolumn{2}{|l|}{\texttt{indoorScene}}                                                                                                                                                     \\ \hline
Tipo de dato                                  & string                                                                                                                                         \\ \hline
Descripción                                   & \begin{tabular}[c]{@{}l@{}}La escena detectada, puede ser cualquiera de las\\ cuatro posibles \(exit, soccer_court, desks, office\)\end{tabular} \\ \hline
Descripción                                   & Escenario reconocido.                                                                                                                          \\ \hline
\cellcolor[HTML]{68CBD0}\textbf{Descripción}  & \begin{tabular}[c]{@{}l@{}}Lista con las respuestas de acuerdo a las \\ características que se solicitaron.\end{tabular}                       \\ \hline
\end{longtable}


\subparagraph{Ejemplo de una petición a la API con cURL.}

cURL es una herramienta en la línea de comandos para transferir
datos usando diferentes protocolos. Por facilidad,
se muestra el uso de la API a través de esta herramienta.
Para solicitar el recurso para procesamiento de imágenes, \texttt{vision} se necesita un token de acceso. El token
se obtiene creando un usuario haciendo una petición al recurso
\texttt{register}. El código para solicitar este servicio con
\texttt{cURL} es el siguiente:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
curl \PYGZhy{}X POST \PYG{l+s+se}{\PYGZbs{}}
http://132.248.180.17/register \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}H \PYG{l+s+s1}{\PYGZsq{}content\PYGZhy{}type: application/json\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}d \PYG{l+s+s1}{\PYGZsq{}\PYGZob{}}
\PYG{l+s+s1}{    \PYGZdq{}username\PYGZdq{} : \PYGZdq{}mock\PYGZus{}user@gmailcom\PYGZdq{},}
\PYG{l+s+s1}{    \PYGZdq{}password\PYGZdq{} : \PYGZdq{}p45sw0rd\PYGZdq{}}
\PYG{l+s+s1}{    \PYGZcb{}\PYGZsq{}}
\end{sphinxVerbatim}

La respuesta de la API es un JSON como el que sigue:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{message}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{User created successfully.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{token}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OFdT6v23Tnw95S8BX2yNR8Os8RB6L4HAnvhTTrfjmxB5UyMaef}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Con el token se pueden hacer las peticiones que se deseen al recurso
\sphinxcode{\sphinxupquote{visión}}. Supongamos que queremos analizar una imagen para encontrar rostros, objetos, etiquetas, traducción 
de texto y clasificación de escenarios. El código para generar la 
petición es el siguiente:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
curl \PYGZhy{}X POST \PYG{l+s+se}{\PYGZbs{}}
http://132.248.180.17/vision \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}H \PYG{l+s+s1}{\PYGZsq{}authorization: OFdT6v23Tnw95S8BX2yNR8Os8RB6L4HAnvhTTrfjmxB5UyMaef\PYGZsq{}} \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}H \PYG{l+s+s1}{\PYGZsq{}content\PYGZhy{}type: application/json\PYGZsq{}} \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}d \PYG{l+s+s1}{\PYGZsq{}\PYGZob{}}
\PYG{l+s+s1}{\PYGZdq{}imageSource\PYGZdq{} : \PYGZdq{}https://www.robotshop.com/blog/en/files/NAO\PYGZhy{}Hanover.jpg\PYGZdq{},}
\PYG{l+s+s1}{   \PYGZdq{}features\PYGZdq{} : [}
\PYG{l+s+s1}{      \PYGZob{}}
\PYG{l+s+s1}{        \PYGZdq{}type\PYGZdq{}: \PYGZdq{}FACE\PYGZus{}RECOGNITION\PYGZdq{}}
\PYG{l+s+s1}{      \PYGZcb{},}
\PYG{l+s+s1}{      \PYGZob{}}
\PYG{l+s+s1}{        \PYGZdq{}type\PYGZdq{} : \PYGZdq{}OBJECT\PYGZus{}DETECTION\PYGZdq{}}
\PYG{l+s+s1}{      \PYGZcb{},}
\PYG{l+s+s1}{      \PYGZob{}}
\PYG{l+s+s1}{        \PYGZdq{}type\PYGZdq{} : \PYGZdq{}LABELS\PYGZus{}DETECTION\PYGZdq{}}
\PYG{l+s+s1}{      \PYGZcb{},}
\PYG{l+s+s1}{      \PYGZob{}}
\PYG{l+s+s1}{        \PYGZdq{}type\PYGZdq{} : \PYGZdq{}OCR\PYGZus{}TRANSLATION\PYGZdq{}}
\PYG{l+s+s1}{      \PYGZcb{},}
\PYG{l+s+s1}{      \PYGZob{}}
\PYG{l+s+s1}{        \PYGZdq{}type\PYGZdq{} : \PYGZdq{}CLASSIFY\PYGZus{}INDOOR\PYGZus{}SCENES\PYGZdq{}}
\PYG{l+s+s1}{      \PYGZcb{}}
\PYG{l+s+s1}{   ]}
\PYG{l+s+s1}{\PYGZcb{}\PYGZsq{}}
\end{sphinxVerbatim}

La respuesta de la API de CloudNAO envía como respuesta el 
subsecuente JSON:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}features\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}labelsDetection\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.9718034}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}name\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}robot\PYGZdq{}}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.94625956}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}name\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}sport venue\PYGZdq{}}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.9407438}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}name\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}technology\PYGZdq{}}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.8791277}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}name\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}machine\PYGZdq{}}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.76215124}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}name\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}arena football\PYGZdq{}}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
        \PYG{p}{]}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}objectDetection\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.9916030764579773}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}category\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}person\PYGZdq{}}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{42}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{158}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{430}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{50}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.9870478510856628}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}category\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}person\PYGZdq{}}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{79}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{115}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{253}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{49}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.9252263307571411}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}category\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}person\PYGZdq{}}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{11}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{148}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{2}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{53}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
                \PYG{l+s+s2}{\PYGZdq{}confidence\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mf}{0.9083054661750793}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}category\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}sports ball\PYGZdq{}}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftY\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{248}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}height\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{50}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}topLeftX\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{219}\PYG{p}{,}
                \PYG{l+s+s2}{\PYGZdq{}width\PYGZdq{}}\PYG{o}{:} \PYG{l+m+mi}{49}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
        \PYG{p}{]}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}indoorScenesClassify\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
            \PYG{l+s+s2}{\PYGZdq{}indoor\PYGZus{}scene\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}soccer\PYGZus{}court\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}errors\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}faceRecognition\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
            \PYG{l+s+s2}{\PYGZdq{}message\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}invalid url was sent\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}ocrTranslation\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
            \PYG{l+s+s2}{\PYGZdq{}message\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Text not found\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}




\subsubsection{Guía para desarrolladores}
\label{\detokenize{chapter_two/desc_cloudnao:documentacion-para-maintainers-de-la-api}}
Esta API puede funcionar de manera individual, no es necesario contar con todos
los componentes de la arquitectura. Puede integrarse en algún otro sistema,
donde se requieran los mismos servicios web. 

Está desarrollada en el lenguaje de programación Python, utilizando el framework
Flask. La siguiente lista muestra las dependencias más importantes:
\begin{itemize}
\item {} 
\sphinxstylestrong{Flask}, un microframework para desarrollar aplicaciones web, y extensiones de éste como:
\begin{itemize}
\item {} 
\sphinxstylestrong{Flask-RESTful}, para construir rápidamente una API REST.

\item {} 
\sphinxstylestrong{Flask-SQLAlchemy}, Es una biblioteca que implementa la técnica ORM (Mapeador Relacional de Objetos), la cual permite consultar y manipular datos de una base de datos usando el paradigma orientado a objetos.

\item {} 
\sphinxstylestrong{Flask-Script}, una interfaz la línea de comandos.

\end{itemize}

\item {} 
\sphinxstylestrong{TensorFlow},  una biblioteca de código abierto para cómputo numérico usando gráficas de flujos de datos.

\item {} 
\sphinxstylestrong{numpy}, una biblioteca para cómputo científico.

\item {} 
\sphinxstylestrong{requests}, una biblioteca para las peticiones HTTP a servicios web.

\end{itemize}

%Para comprender mejor este elemento, en las siguientes subsecciones se describen
%cada una de las herramientas utilizadas, primero el framework Flask, junto con
%sus extensiones y las otras bibliotecas mencionadas. Después explico su
%integración en una sola aplicación, y finalmente las opciones de
%configuración e instalación, así como su despliegue en un servidor.



\paragraph{Descripción de los módulos principales}
\label{\detokenize{chapter_two/desc_cloudnao:codigo}}
La aplicación está compuesta por diferentes por módulos
divididos de la siguiente forma:
%está levemente basada en la definida en el libro
%\sphinxstylestrong{Flask Web Development} de Miguel Grinberg, pero adaptada para una API REST.
%Esta quedó como sigue.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
├── app
│   ├── credentials.json
│   ├── \PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py
│   ├── models
│   │   ├── \PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py
│   │   └── user\PYGZus{}model.py
│   ├── resources
│   │   ├── \PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py
│   │   ├── token.py
│   │   ├── user.py
│   │   └── vision.py
│   ├── tf\PYGZus{}models
│   │   ├── category\PYGZus{}idx.json
│   │   ├── indoor\PYGZus{}scenes\PYGZus{}classifier.py
│   │   ├── indoor\PYGZus{}scenes\PYGZus{}lar
│   │   ├── \PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py
│   │   ├── object\PYGZus{}detection.py
│   │   └── ssd\PYGZus{}mobilenet\PYGZus{}v1\PYGZus{}coco\PYGZus{}11\PYGZus{}06\PYGZus{}2017
│   ├── tpa\PYGZus{}client\PYGZus{}libraries
│   │   ├── google\PYGZus{}cloud\PYGZus{}speech.py
│   │   ├── google\PYGZus{}cloud\PYGZus{}translation.py
│   │   ├── google\PYGZus{}cloud\PYGZus{}vision.py
│   │   ├── \PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py
│   │   ├── kairos\PYGZus{}client.py
│   │   └── wit\PYGZus{}api.py
│   └── utils
│       ├── auxiliar\PYGZus{}functions.py
│       ├── image\PYGZus{}utils.py
│       ├── \PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py
│       └── requests\PYGZus{}utils.py
├── config.py
├── Dockerfile
├── manage.py
├── README.md
└── requirements.txt
\end{sphinxVerbatim}

En el nivel más alto están:
\begin{itemize}
\item {} 
La aplicación de Flask en un paquete llamado \sphinxstyleemphasis{app}. Este es el núcleo del proyecto, contiene los modelos para la base de datos, los recursos, clientes de servicios web de terceros, etc.

\item {} 
El archivo que almacena las opciones de configuración \sphinxstyleemphasis{config.py}.

\item {} 
El script que ejecuta al aplicación \sphinxstyleemphasis{manage.py}.

\item {} 
Los archivos \sphinxstyleemphasis{README.md} y \sphinxstyleemphasis{requirements.txt}, y la carpeta \sphinxstyleemphasis{venv}, contienen una breve descripción del proyecto, la lista de dependencias y el ambiente virtual de Python, respectivamente.

\end{itemize}

En las siguientes secciones se documentan las partes más importantes del
proyecto, el paquete \sphinxstyleemphasis{app}, \sphinxstyleemphasis{config.py} y \sphinxstyleemphasis{manage.py}.


\subparagraph{Aplicación (\sphinxstyleemphasis{app}).}
\label{\detokenize{chapter_two/desc_cloudnao:aplicacion-app}}\label{\detokenize{chapter_two/desc_cloudnao:module-app}}\index{app (módulo)}
La aplicación en Flask de la API de CloudNAO, está compuesta por varios paquetes,
los recursos, los modelos para la base datos, los clientes de los servicios web de
terceros, modelos de Tensorflow y módulos auxiliares.


\subparagraph{Modelos (\sphinxstyleemphasis{models}).}
\label{\detokenize{chapter_two/desc_cloudnao:module-app.models}}\label{\detokenize{chapter_two/desc_cloudnao:modelos-models}}\index{app.models (módulo)}
Este paquete contiene los modelos de la base de datos, usando SQLAlchemy.
\newline
\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-app.models.user_model}}\index{app.models.user\_model (módulo)}\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-user_model}}\index{user\_model (módulo)}\index{UserModel (clase en app.models.user\_model)}


\codedocumentation{
\sphinxbfcode{class }\sphinxcode{app.models.user\_model.}\sphinxbfcode{UserModel}{(\emph{username}, \emph{password}})}
Una clase pública para el modelo del usuario que se almacena en la base
de datos.
El nombre de la tabla en la base de datos es \sphinxcode{users}. Los atributos de esta
última se describen en la tabla \ref{desc_cloudnao:user-model-attr}.

\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Descripción de los atributos del modelo User\label{desc_cloudnao:user-model-attr}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstylethead{ 
Atributo
\unskip}\relax &\sphinxstylethead{ 
Descripción
\unskip}\relax \\
\hline
id
&
El id del usuario, es una llave primaria.
\\
\hline
username
&
Una cadena con el nombre del usuario, es única.
\\
\hline
password\_hash
&
Una cadena que obtenida de una función hash aplicada a la contraseña original
\\
\hline
access\_token
&
Una cadena única que sirve como llave de autorización al hacer peticiones a los recursos de la API.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

El siguiente ejemplo muestra la creación e inserción de un usuario en la
base de datos.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{models}\PYG{n+nn}{.}\PYG{n+nn}{user\PYGZus{}model} \PYG{k}{import} \PYG{n}{UserModel}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{rick\PYGZus{}deckard} \PYG{o}{=} \PYG{n}{UserModel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{rick.deckard@sfpd.gov}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{4m1r34l2019}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{rick\PYGZus{}deckard}\PYG{o}{.}\PYG{n}{username}
\PYG{g+go}{\PYGZsq{}rick.deckard@sfpd.gov\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{rick\PYGZus{}deckard}\PYG{o}{.}\PYG{n}{password\PYGZus{}hash}
\PYG{g+go}{\PYGZsq{}pbkdf2:sha256:50000\PYGZdl{}oSNfC6Y1\PYGZdl{}e54e06fcfc0a608795fe32147e4a...\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{rick\PYGZus{}deckard}\PYG{o}{.}\PYG{n}{access\PYGZus{}token}
\PYG{g+go}{\PYGZsq{}Z9WxxgXeYxIOg8N6hD6Jj4UM79fJTf4uAR3VAUyFUbXWK8kl4D\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{UserModel}\PYG{o}{.}\PYG{n}{query}\PYG{o}{.}\PYG{n}{all}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{[]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{rick\PYGZus{}deckard}\PYG{o}{.}\PYG{n}{save\PYGZus{}to\PYGZus{}db}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{UserModel}\PYG{o}{.}\PYG{n}{query}\PYG{o}{.}\PYG{n}{all}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{[\PYGZlt{}UserModel 1\PYGZgt{}]}
\end{sphinxVerbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subparagraph{Recursos (\sphinxstyleemphasis{resources}).}
\label{\detokenize{chapter_two/desc_cloudnao:recursos-resources}}\label{\detokenize{chapter_two/desc_cloudnao:module-app.resources}}\index{app.resources (módulo)}
En este paquete se definen los recursos que representan a los servicios que
la API estará brindando. Desde el registro de un usuario, obtención de un nuevo
token de acceso, hasta el procesamiento de imágenes.
\newline
\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-app.resources.user}}\index{app.resources.user (módulo)}\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-user}}\index{user (módulo)}\index{UserRegister (clase en app.resources.user)}

\codedocumentation{
\sphinxbfcode{class }\sphinxcode{app.resources.user.}\sphinxbfcode{UserRegister}}
Una clase pública que representa un recurso de la API REST, para el
almacenamiento de nuevos usuarios. Hereda de la clase \sphinxcode{Resource} de
\sphinxcode{flask\_restful} y usa un objeto de la clase \sphinxcode{RequestParser} para definir
y parsear los argumentos de cada petición HTTP. Sólo se define el método
POST, para la creación de usuarios.

Son dos los argumentos requeridos para poder solicitar este recurso,
\sphinxcode{username}, el nombre del usuario, y \sphinxcode{password}, la contraseña. Si alguno
de estos dos no es enviado, la instancia de \sphinxcode{RequestParser} envía un mensaje
de error.
\index{post() (método de app.resources.user.UserRegister)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:app.resources.user.UserRegister.post}}\pysiglinewithargsret{\sphinxbfcode{post}}{}{}
Método para añadir un nuevos usuario a la base de datos, a través de
un POST. Se verifica si no hay un usuario con el mismo nombre. Si existe,
se envía un mensaje de error y el código de estado \sphinxstyleemphasis{400} (\sphinxstyleemphasis{Bad Request}).
Si no, se envía un mensaje de éxito y código de estado \sphinxstyleemphasis{201} (\sphinxstyleemphasis{Created}).

Un ejemplo del cuerpo de la petición y la respuesta se muestran a
continuación:
\begin{quote}\begin{description}
\item[{Petición}] \leavevmode
\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}username\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}rick.deckard@sfpd.gov\PYGZdq{}}
  \PYG{l+s+s2}{\PYGZdq{}password\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}4m1r34l2019\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Respuesta}] \leavevmode
\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}message\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}User created successfully.\PYGZdq{}}
  \PYG{l+s+s2}{\PYGZdq{}token\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}Z9WxxgXeYxIOg8N6hD6Jj4UM79fJTf4uAR3VAUyFUbXWK8kl4D\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\end{fulllineitems}


\codedocumentation{
\sphinxbfcode{class }\sphinxcode{app.resources.token.}\sphinxbfcode{Token}}
Clase pública que representa un token en la API REST. Permite la obtención
de un nuevo token de acceso a la API, usando un método POST y enviado en el
mensaje el nombre de usuario y la contraseña. Todo
esto usando \sphinxcode{Resource} y \sphinxcode{RequestParser} de \sphinxcode{flask\_restful}.

Solo se define el método POST, para generar un nuevo token de acceso.
\index{post() (método de app.resources.token.Token)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:app.resources.token.Token.post}}\pysiglinewithargsret{\sphinxbfcode{post}}{}{}
Genera un nuevo token de acceso para el usuario que envía un POST
a este recurso. Se requiere enviar el nombre del usuario y la contraseña.
Si estos son válidos se genera un nuevo token y se guarda en la base
de datos. Se envía como respuesta el nuevo token, con un código de
estado \sphinxstyleemphasis{201} (\sphinxstyleemphasis{Created}).

El cuerpo de la petición y la respuesta, si todo es exitoso, son los
siguientes:
\begin{quote}\begin{description}
\item[{Petición}] \leavevmode
\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}username\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}rick.deckard@sfpd.gov\PYGZdq{}}
  \PYG{l+s+s2}{\PYGZdq{}password\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}4m1r34l2019\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Respuesta}] \leavevmode
\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}token\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}ue6yCsfMBX3DOoMhieBgbY6eA12tDWsZkOnXO00qPOqglWJ6Kq\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\end{fulllineitems}

\codedocumentation{
\sphinxbfcode{class }\sphinxcode{app.resources.vision.}\sphinxbfcode{Vision}}
Clase pública del recurso de la API REST para solicitar el procesamiento
de imágenes. Acepta peticiones de tipo \sphinxcode{POST} en cuyo cuerpo van las
características que se desean computar. Las aceptadas son las siguientes:
\begin{itemize}
\item {}
\texttt{FACE\_RECOGNITION}

\item {}
\texttt{OBJECT\_DETECTION}

\item {}
\texttt{LABELS\_DETECTION}

\item {}
\texttt{OCR\_TRANSLATION}

\item {}
\texttt{FACE\_ENROLL}

\item {}
\texttt{CLASSIFY\_INDOOR\_SCENES}

\end{itemize}
\index{post() (método de app.resources.vision.Vision)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:app.resources.vision.Vision.post}}\pysiglinewithargsret{\sphinxbfcode{post}}{}{}
Define el método \sphinxcode{POST} a este recurso. Requiere de enviar un token
de acceso en los encabezados para poder ejecutarse. Solamente maneja la
petición y corre la funciones que se piden de acuerdo a lo que se
solicita en el cuerpo del mensaje.

Aquí se unen en una sola las respuestas de los módulos dentro de
\sphinxcode{app.tf\_models} y \sphinxcode{app.tpa\_client\_libraries}.

\end{fulllineitems}



\subparagraph{Modelos de Tensorflow (\sphinxstyleemphasis{tf\_models}).}
En este paquete se encuentran los módulos encargados de la 
detección de objetos y la clasificación de escenarios usando
TensorFlow.
\newline
\codedocumentation{\sphinxbfcode{class }\sphinxcode{app.tf\_models.object\_detection.}\sphinxbfcode{ObjectDetectionTensorflow}}
Una clase pública que utiliza un modelo pre-entrenado para la detección
de múltiples objetos en una imagen. El modelo utilizado es
\sphinxcode{ssd\_mobilenet\_v1\_\\coco} provisto por la API de TensorFlow y entrenado con el
conjunto de imágenes de \sphinxhref{http://cocodataset.org/}{COCO}.

El siguiente ejemplo
muestra un simple uso de la clase.

%\begin{figure}[htbp]
%\centering
%
%\subfloat[]{{\includegraphics[width=5cm]{object_detection_image}}}%
%\qquad
%\subfloat[]{{\includegraphics[width=6cm]{object_detection_boxes}}}%
%\caption{Imagen utilizada en el ejemplo. (b) muestra los cuadros delimitadores de lo objetos encontrados.}
%
%\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{tf\PYGZus{}models}\PYG{n+nn}{.}\PYG{n+nn}{object\PYGZus{}detection} \PYG{k}{import} \PYG{n}{ObjectDetectionTensorflow}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{object\PYGZus{}detector} \PYG{o}{=} \PYG{n}{ObjectDetectionTensorflow}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{image\PYGZus{}base64} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/9j/4AAQSkZJRgABAQEAYABgAAD/2...}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{object\PYGZus{}detector}\PYG{o}{.}\PYG{n}{object\PYGZus{}detection}\PYG{p}{(}\PYG{n}{image\PYGZus{}base64}\PYG{p}{)}
\PYG{g+go}{[\PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.8984639048576355, \PYGZsq{}category\PYGZsq{}: \PYGZsq{}car\PYGZsq{}, \PYGZsq{}topLeftY\PYGZsq{}: 175.0, \PYGZsq{}height\PYGZsq{}: 129.0, \PYGZsq{}width\PYGZsq{}: 154.0, \PYGZsq{}topLeftX\PYGZsq{}: 0.0\PYGZcb{},..., \PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.6006952524185181, \PYGZsq{}category\PYGZsq{}: \PYGZsq{}person\PYGZsq{}, \PYGZsq{}topLeftY\PYGZsq{}: 189.0, \PYGZsq{}height\PYGZsq{}: 109.0, \PYGZsq{}width\PYGZsq{}: 45.0, \PYGZsq{}topLeftX\PYGZsq{}: 164.0\PYGZcb{}]}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\end{sphinxVerbatim}



\codedocumentation{\sphinxbfcode{class }\sphinxcode{app.tf\_models.indoor\_scenes\_classifier.}\sphinxbfcode{ImageClassifier}}
Una clase pública que utiliza que utiliza una red neuronal
convolucional implementada en Tensorflow para clasificar en cuatro
clases una imagen. Las clases son:
desks,
exit,
office,
y soccer\_court.

Es la clase que carga el modelo ya entrenado, simplemente carga
la gráfica de cómputo que diseñamos con los parámetros
aprendidos. El clasificador puede
recibir una imagen codificada en base64 o su URL. El resultado
es un diccionario que pueda ser enviado como respuesta en la API
REST.

El siguiente ejemplo
muestra un simple uso de la clase. La imagen utilizada es la
de la figura \ref{fig:nao_soccer_court}
codificada en base 64.

\begin{figure}[htbp]
\centering
\caption{Cancha de entrenamiento del robot NAO.\label{fig:nao_soccer_court}}
\includegraphics[scale=0.3]{{soccer1}.jpg}
\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{tf\PYGZus{}models}\PYG{n+nn}{.}\PYG{n+nn}{indoor\_scenes\_classifier} \PYG{k}{import} \PYG{n}{ImageClassifier}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test\PYGZus{}image} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/9j/4AAQSkZJRgABAQAAAQABAAD/2...}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clasifier} \PYG{o}{=} \PYG{n}{ImageClassifier}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{classifier}\PYG{o}{.}\PYG{n}{classify\PYGZus{}image}\PYG{p}{(}\PYG{n}{test\PYGZus{}image}\PYG{p}{)}
\PYG{g+go}{\PYGZob{}\PYGZsq{}indoor\PYGZus{}scene\PYGZsq{}: \PYGZsq{}soccer\PYGZus{}court\PYGZsq{}\PYGZcb{}}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\end{sphinxVerbatim}

\subparagraph{Cliente de servicios web de terceros (\sphinxstyleemphasis{tpa\_client\_libraries})}
\label{\detokenize{chapter_two/desc_cloudnao:cliente-de-servicios-web-de-terceros-tpa-client-libraries}}\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-app.tpa_client_libraries.google_cloud_translation}}\index{app.tpa\_client\_libraries.google\_cloud\_translation (módulo)}\index{GoogleCloudTranslation (clase en app.tpa\_client\_libraries.google\_cloud\_translation).}

En este paquete se encuentran los módulos para hacer las peticiones
a las API REST de los servicios en la nube de Google Cloud, Kairos
y Wit.ai.
\newline

\codedocumentation{\sphinxbfcode{class }\sphinxcode{app.tpa\_client\_libraries.google\_cloud\_translation.}\sphinxbfcode{GoogleCloudTranslation}}

Una clase pública que se conecta a la API de traducción de Google Cloud,
la cual permite traducir una cadena dada en un cualquier idioma admitido.
Hay tres métodos que provee la API; \sphinxcode{translate}, que recibe una cadena y
retorna su traducción, \sphinxcode{detect}, para detectar el idioma de un texto y
\sphinxcode{languages}, que retorna la lista de todos los idiomas disponibles para
la traducción.

El usado es \sphinxcode{translate}, a través de un \sphinxcode{POST} a
\sphinxcode{https://translation.googleapis.com/language/translate/v2}. El cuerpo
del mensaje HTTP debe tener al menos dos parámetros \sphinxcode{q} y \sphinxcode{target},
el texto de entrada y el código del lenguaje al que se traducirá el texto
de entrada, respectivamente.

En el siguiente fragmento de código en una terminal de Python interactiva
se muestra cómo utilizar este módulo.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{tpa\PYGZus{}client\PYGZus{}libraries}\PYG{n+nn}{.}\PYG{n+nn}{google\PYGZus{}cloud\PYGZus{}translation} \PYG{k}{import} \PYG{n}{GoogleCloudTranslation}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{translate} \PYG{o}{=} \PYG{n}{GoogleCloudTranslation}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{translate}\PYG{o}{.}\PYG{n}{translate}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cuervo, cuervo, no soporto más tu mirada}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{en}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{\PYGZob{}\PYGZsq{}sourceLanguage\PYGZsq{}: \PYGZsq{}es\PYGZsq{}, \PYGZsq{}targetText\PYGZsq{}: \PYGZsq{}Crow, crow, I can not stand your gaze anymore\PYGZsq{}, \PYGZsq{}sourceText\PYGZsq{}: \PYGZsq{}Cuervo, cuervo, no soporto más tu mirada\PYGZsq{}\PYGZcb{}}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\end{sphinxVerbatim}

\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-app.tpa_client_libraries.google_cloud_vision}}\index{app.tpa\_client\_libraries.google\_cloud\_vision (módulo)}\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-google_cloud_vision}}\index{google\_cloud\_vision (módulo)}\index{GoogleCloudVision (clase en app.tpa\_client\_libraries.google\_cloud\_vision)}


\codedocumentation{\sphinxbfcode{class }\sphinxcode{app.tpa\_client\_libraries.google\_cloud\_vision.}\sphinxbfcode{GoogleCloudVision}}

Una clase pública para integrar en la aplicación dos de las características
ofrecidas por Google Cloud Vision, el reconocimiento óptico de caracteres y
el etiquetado de imágenes, usando su API REST.

El recurso de la API de Google Cloud Vision utilizado es \sphinxcode{v1.images},
y la URL es
\sphinxcode{https://vision.googleapis.com/v1/images:annotate}. Por lo que hacer
un \sphinxcode{POST} al URL anterior ejecuta el procesamiento de un lote de imágenes.

El cuerpo del mensaje HTTP en la petición a la API de Google Cloud Vision,
debe tener la siguiente estructura.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}requests\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
    \PYG{p}{\PYGZob{}}
      \PYG{l+s+s2}{\PYGZdq{}features\PYGZdq{}}\PYG{o}{:} \PYG{p}{[}
        \PYG{p}{\PYGZob{}}
          \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}TEXT\PYGZus{}DETECTION\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}\PYG{p}{,}
        \PYG{p}{\PYGZob{}}
          \PYG{l+s+s2}{\PYGZdq{}type\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}LABEL\PYGZus{}DETECTION\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}
      \PYG{p}{]}\PYG{p}{,}
      \PYG{l+s+s2}{\PYGZdq{}image\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}content\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}source\PYGZdq{}}\PYG{o}{:} \PYG{p}{\PYGZob{}}
          \PYG{l+s+s2}{\PYGZdq{}imageUri\PYGZdq{}}\PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}
      \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}
  \PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

En el parámetro \sphinxcode{features} solo añadimos las dos que utilizamos. El objeto
\sphinxcode{image} contiene la imagen que se desea analizar, y acepta la imagen codificada
en base64 (\sphinxcode{content}) o un URL (\sphinxcode{imageUri}).

Además de el cuerpo con la imagen es necesaria una API Key en los parámetros
del URL.

El siguiente ejemplo muestra un uso simple de esta clase cliente de la API
de Google Cloud.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{tpa\PYGZus{}client\PYGZus{}libraries}\PYG{n+nn}{.}\PYG{n+nn}{google\PYGZus{}cloud\PYGZus{}vision} \PYG{k}{import} \PYG{n}{GoogleCloudVision}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{vision} \PYG{o}{=} \PYG{n}{GoogleCloudVision}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{vision}\PYG{o}{.}\PYG{n}{text\PYGZus{}annotations\PYGZus{}description}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://new2.fjcdn.com/comments/Quote+from+this+scene+in+blade+runner+1982+dayum+son+\PYGZus{}fbf2a406e9c802ff492e414c34fff791.jpeg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+go}{\PYGZob{}\PYGZsq{}text\PYGZsq{}: \PYGZsq{}You reach down and you flip the\PYGZbs{}ntortoise over on its back, Leon.\PYGZbs{}n\PYGZsq{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{vision}\PYG{o}{.}\PYG{n}{label\PYGZus{}annotations\PYGZus{}description}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://new2.fjcdn.com/comments/Quote+from+this+scene+in+blade+runner+1982+dayum+son+\PYGZus{}fbf2a406e9c802ff492e414c34fff791.jpeg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+go}{[\PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.76214135, \PYGZsq{}name\PYGZsq{}: \PYGZsq{}photo caption\PYGZsq{}\PYGZcb{}, \PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.569268, \PYGZsq{}name\PYGZsq{}: \PYGZsq{}film\PYGZsq{}\PYGZcb{}, \PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.55112684, \PYGZsq{}name\PYGZsq{}: \PYGZsq{}screenshot\PYGZsq{}\PYGZcb{}]}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\end{sphinxVerbatim}

\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-app.tpa_client_libraries.kairos_client}}\index{app.tpa\_client\_libraries.kairos\_client (módulo)}\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-kairos}}\index{kairos (módulo)}\index{Kairos (clase en app.tpa\_client\_libraries.kairos\_client)}

\codedocumentation{\sphinxbfcode{class }\sphinxcode{app.tpa\_client\_libraries.kairos\_client.}\sphinxbfcode{Kairos}}
Una clase pública que sirve como cliente para conectarse a dos servicios
que brinda la API de Kairos, el almacenamiento de rostros en una galería en la nube, y
la identificación de caras previamente guardadas.

Para ocupar estos servicios la API de Kairos provee los recursos \sphinxcode{enroll} y
\sphinxcode{recognize}, los cuales soportan el método \sphinxcode{POST} y tienen como
URL base \sphinxcode{http://api.kairos.com/}. Para hacer estas peticiones se
necesita una forma de autenticación, y esta es a través de los encabezados
del mensaje HTTP, enviando en estos un id y una llave de la aplicación.

El cuerpo del \sphinxcode{POST} a \sphinxcode{recognize} tiene necesita al dos parámetros; la
imagen, que puede ser su URL o la codificación en base 64
y el nombre de la galería de donde de donde se desea identificar el rostro.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}image\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}gallery\PYGZus{}name\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

El cuerpo del \sphinxcode{POST} a {enroll} requiere de al menos tres argumentos;
la imagen, el nombre de la galería y el identificador del rostro, que
comúnmente es el nombre de la persona con esa cara.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}image\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}subject\PYGZus{}id\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}gallery\PYGZus{}name\PYGZdq{}} \PYG{o}{:} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Un ejemplo del uso del módulo.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{tpa\PYGZus{}client\PYGZus{}libraries}\PYG{n+nn}{.}\PYG{n+nn}{kairos\PYGZus{}client} \PYG{k}{import} \PYG{n}{Kairos}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{face} \PYG{o}{=} \PYG{n}{Kairos}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{face}\PYG{o}{.}\PYG{n}{enroll}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{http://www.indiewire.com/wp\PYGZhy{}content/uploads/2017/10/triboro\PYGZus{}build03.jpeg?w=780}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Rachael}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{\PYGZob{}\PYGZsq{}faceEnroll\PYGZsq{}: \PYGZob{}\PYGZsq{}gender\PYGZsq{}: \PYGZsq{}M\PYGZsq{}, \PYGZsq{}width\PYGZsq{}: 235, \PYGZsq{}topLeftY\PYGZsq{}: 232, \PYGZsq{}confidence\PYGZsq{}: 0.99931, \PYGZsq{}height\PYGZsq{}: 235, \PYGZsq{}topLeftX\PYGZsq{}: 232\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{face}\PYG{o}{.}\PYG{n}{recognize}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://i.ytimg.com/vi/j4jIJB8c1I8/maxresdefault.jpg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{\PYGZob{}\PYGZsq{}faceRecognize\PYGZsq{}: \PYGZob{}\PYGZsq{}subject\PYGZus{}id\PYGZsq{}: \PYGZsq{}Rachael\PYGZsq{}, \PYGZsq{}width\PYGZsq{}: 342, \PYGZsq{}topLeftY\PYGZsq{}: 165, \PYGZsq{}confidence\PYGZsq{}: 0.63092, \PYGZsq{}height\PYGZsq{}: 342, \PYGZsq{}topLeftX\PYGZsq{}: 366\PYGZcb{}\PYGZcb{}}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\end{sphinxVerbatim}


\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-app.tpa_client_libraries.wit_api}}\index{app.tpa\_client\_libraries.wit\_api (módulo)}\phantomsection\label{\detokenize{chapter_two/desc_cloudnao:module-wit_api}}\index{wit\_api (módulo)}\index{WitAPI (clase en app.tpa\_client\_libraries.wit\_api)}


\codedocumentation{\sphinxbfcode{class }\sphinxcode{app.tpa\_client\_libraries.wit\_api.}\sphinxbfcode{WitAPI}}
Una clase pública donde se hacen las peticiones HTTP
a Wit.ai y para extraer el significado del audio o texto. Funciona como
un módulo cliente para solicitar los recursos de \sphinxcode{/message} y \sphinxcode{/speech}.
Estos recursos tiene la función de hallar información estructurada dentro
de una oración.

En seguida se muestra cómo utilizar el método \sphinxcode{message()} para
enlistar las entidades encontradas en una cadena de texto.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{app}\PYG{n+nn}{.}\PYG{n+nn}{tpa\PYGZus{}client\PYGZus{}libraries}\PYG{n+nn}{.}\PYG{n+nn}{wit\PYGZus{}api} \PYG{k}{import} \PYG{n}{WitAPI}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wit\PYGZus{}example} \PYG{o}{=} \PYG{n}{WitAPI}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wit\PYGZus{}example}\PYG{o}{.}\PYG{n}{message}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Lee el texto de esta fotografía}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{\PYGZob{}\PYGZsq{}textDetect\PYGZsq{}: [\PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.76588128565519, \PYGZsq{}type\PYGZsq{}: \PYGZsq{}value\PYGZsq{}, \PYGZsq{}value\PYGZsq{}: \PYGZsq{}lee\PYGZsq{}\PYGZcb{}, \PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.95853105168152, \PYGZsq{}type\PYGZsq{}: \PYGZsq{}value\PYGZsq{}, \PYGZsq{}value\PYGZsq{}: \PYGZsq{}texto\PYGZsq{}\PYGZcb{}], \PYGZsq{}photography\PYGZsq{}: [\PYGZob{}\PYGZsq{}confidence\PYGZsq{}: 0.65220641878769, \PYGZsq{}type\PYGZsq{}: \PYGZsq{}value\PYGZsq{}, \PYGZsq{}value\PYGZsq{}: \PYGZsq{}fotografía\PYGZsq{}\PYGZcb{}]\PYGZcb{}}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\end{sphinxVerbatim}
\index{message() (método de app.tpa\_client\_libraries.wit\_api.WitAPI)}


\subparagraph{Utilidades (\sphinxstyleemphasis{utils})}
\label{\detokenize{chapter_two/desc_cloudnao:utilidades-utils}}\index{make\_request() (en el módulo app.utils.requests\_utils)}

Este paquete incluye funciones auxiliares
para hacer peticiones HTTP utilizando la biblioteca 
\texttt{requests} de Python, funciones para validar
la autenticación y cargar una imagen en un arreglo
de \texttt{numpy}.


\paragraph{Configuración y ejecución}
\label{\detokenize{chapter_two/desc_cloudnao:configuracion-y-ejecucion}}
La aplicación cuenta con varias opciones de configuración, principalmente
para \sphinxcode{SQLAlchemy} y para activar el debugging durante la ejecución.

Para la ejecución de la aplicación simplemente se corre el
script \sphinxstyleemphasis{manage.py}. Eligiendo ya sea la interfaz de línea de comandos:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} python manage.py shell
\end{sphinxVerbatim}

O lanzar el servidor:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} python manage.py runserver
\end{sphinxVerbatim}


\subparagraph{config.py}
\label{\detokenize{chapter_two/desc_cloudnao:config-py}}\label{\detokenize{chapter_two/desc_cloudnao:module-config}}\index{config (módulo)}
Programa que establece las opciones de configuración para la
aplicación.
\index{Config (clase en config)}


\subparagraph{manage.py}
\label{\detokenize{chapter_two/desc_cloudnao:module-manage}}\label{\detokenize{chapter_two/desc_cloudnao:manage-py}}\index{manage (módulo)}
El programa que inicia la aplicación.
\index{create\_tables() (en el módulo manage)}

